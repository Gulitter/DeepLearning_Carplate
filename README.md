<img width="240" height="158" alt="image" src="https://github.com/user-attachments/assets/53722b15-e05a-418d-b3c7-02844e8d0e4e" /># DeepLearning_Carplate
2023 3인 프로젝트(리더)
<img width="739" height="411" alt="image" src="https://github.com/user-attachments/assets/341c4629-5ae3-43ab-809a-918f8ee8a2c1" />

# 목적

일상생활에서 차의 번호판을 인식해야 하는데 번호판이 기울어져 있어서 확인하기 힘든 것을 개선하고 번호판 인식의 자동화를 목적으로 주제를 선정하였습니다.

사진에서 특정 물체나 글자를 추출 해야 하는 경우 어떤 방식으로 구현해야 가장 효율적으로 구현할 수 있는지비교를 하기위해 주제를 선정하였습니다.


# 과정
<img width="1560" height="363" alt="image" src="https://github.com/user-attachments/assets/0771d4f0-5ca4-418c-b4d6-7c257d2f36ef" />

1. 번호판 탐지 모델을 사용하여 번호판을 인식
2. Bounding Box 크기로 잘려진 이미지를 그레이 스케일 후 관심영역, 비관심영역을 임계 값을 통해 이진화 후 외곽선 검출 및 근사화
3. 기울어진 번호판을 3X3 투시변환행렬을 통한 기하학적 변환
4. 글자 인식모델을 통해 글자 예측

# 번호판 탐지 모델 - 데이터셋
1. 한국 번호판 데이터셋은 가까이에서  찍힌 데이터셋만 존재하기에  해외 번호판 데이터셋 으로 차 사진에서  번호판의 위치를 파악할 수 있도록 직사각형으로 라벨링.  (432장)
2. 가까이에서 찍힌 사진에서도 번호판의 위치를 정밀하게 파악할 수 있도록 라벨링. (200장)
3. 예측 시 번호판이 짤리지 않도록 여유있게 라벨링.
4. Yolov5모델 중 중간 정도의 정확도와 속도를 가진 yolov5x모델을 사용해서 번호판데이터셋 600장을 학습.
5. Validation은 102장을 사용해서  1000번 학습.

# 번호판 탐지 모델 - 학습
<img width="1345" height="585" alt="image" src="https://github.com/user-attachments/assets/f213ee76-34f6-4691-abdd-fc86691f0720" />

<img width="1876" height="714" alt="image" src="https://github.com/user-attachments/assets/d17ac229-aec4-40d5-8a1c-aa809728f643" />

# 번호판 꼭짓점 예측 모델 - 데이터셋
1. Yolo로 예측한 모델은 직사각형으로 예측하기 때문에 번호판의 네 모세리에 대한 좌표값은 알 수 없다.  -> 꼭짓점 예측 모델 필요
2. 입력 사진은 yolo로 예측된 사진을 사용할 것이기 때문에 가까이에서 찍힌 한국어 번호판 데이터셋을 사용.
3. 번호판의 모서리 좌표를 일일이 마우스로 찍어서 라벨링 하기에는 시간적, 노동적으로 비용이 많이 들기에 그레이 스케일 후 관심영역, 비관심영역을 임계 값을 통해 이진화 후 외곽선 검출 및 근사화하여  확인 후 해당 사진의 인덱스를 저장.
4. Yolo로 예측한 사진의 크기가 모두 다르기 때문에 입력 사진의 크기를 모두 똑같이 하기 위해 yolo가 예측한 범위를 제외한 부분에서 사진을 따서 정사각형 이미지로 만든 뒤 사이즈 조절을 통해 학습할 이미지로 사용하여 2000번 학습

   
<img width="1710" height="606" alt="image" src="https://github.com/user-attachments/assets/89e2b63a-a458-4898-ac53-8e3191c8669d" />

그레이 스케일 후 관심영역, 비관심영역을 임계 값을 통해 이진화 후 외곽선 검출 및 근사화하여  확인

<img width="1309" height="488" alt="image" src="https://github.com/user-attachments/assets/0646aef4-4b7f-4cb0-9ed3-e42713199d2d" />

라벨링한 좌표를 이용해서 전단 변환 및 번호판의 위치 이동, 색상변환, 밝기변환, 흐림효과, 채도변환,  salt_pepper효과를 랜덤으로 적용하여 전처리

# 번호판 꼭짓점 예측 모델 - 학습
<img width="1369" height="580" alt="image" src="https://github.com/user-attachments/assets/280fbb21-4358-4bf2-8533-e7c76ed1c305" />

# 글자 인식 모델 - 데이터셋
1. Align으로 예측한 이미지를 투시변환한 사진을 입력으로 사용 (256*128)
2. Yolo 모델과 Align모델을 적용했을 때 제대로 예측된 사진만 확인하여 해당 사진의 인덱스를 저장함으로써 라벨링.
3. 학습한 글자는  48개로 다음과 같음
'가', '나', '다', '라', '마', '자', '거', '너', '더', '러', '머', '버', '서', '어', '아', '육', '저', '고', '노', '도', '로', '모', '보', '소', '오', '조', '구', '누', '두', '루', '무', '부', '수', '우', '주', '허', '하', '호', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9’ 
4. 글자 라벨링은 데이터셋에 포함된 데이터를 인덱스로 필요한 데이터만 사용하였고,  train 1600장, validation 400장 사용하여 5000번 학습.

<img width="1114" height="594" alt="image" src="https://github.com/user-attachments/assets/754b6e97-1ae2-48f2-9117-dd8473f86c2a" />

과적합 및 정확도를 올리기위해 다양한 transform을 적용한 사진을 추가하여 학습  

# 글자 인식 모델 - 학습
<img width="1347" height="554" alt="image" src="https://github.com/user-attachments/assets/55c47f89-00b9-4627-9dc3-60f6b54db88b" />

<img width="1880" height="364" alt="image" src="https://github.com/user-attachments/assets/a82077ee-53ff-4a4e-aa32-d594ba9ba5fa" />

# 코드
실시간 처리를 위한 최대한 빠른 처리를 위해 여러가지 환경에서 테스트.
CPU: i7-11800H 
Gpu: RTX3080
OS: 우분투 20.04
 
기준으로 측정


# 결론
- 사진을 1장만 처리해야 하는 경우는 Opencv Cuda버전이 아닌 기본 패키지 버전을 사용하는 것이 가장 빠르며, 이 경우 C++과 Python의 속도는 비슷하다.
- 전반적으로 C++의 속도가 Python보다 빠르게 측정되었으며, Cuda를 적용해야 하는 경우 C언어를 사용하는 Cuda 특성상 C++이 더욱 적용하기 용이하며, 속도 또한 빠르게 측정되었다.
- 실시간으로 처리해야 하는 경우는 C++이 Python보다 약 1.25배 빠르게 측정되었고, 여러 사진을 동시에 처리해야 하는 경우는 약 1.6배 빠르게 측정되었다.
- CPU와 GPU의 성능에 따라 결과가 달라질 수 있으며, Cuda를 효율적으로 사용하기 위해서는 메모리 또한 고려되어야 한다.
- 주차장 차단기에 적용해야 하는 경우  단순히 속도만 생각했을 때는 거리센서를 이용하여 차량이 감지되면 사진을 1장 찍어서 CPU로 처리하는 것이 속도가 가장 빠를 것으로 예상되지만,\
- 번호판이 한 번에 감지되지 않을 수 있기 때문에, 거리센서에 감지되었을 때 여러장을 C++언어에 Cuda를 적용한 코드로 처리하는 것이 정확도와 속도 측면 모두 효율적으로 작동할 수 있을 것으로 예상되고, 비용적인 측면까지 고려한다면 C++에서 CPU를 사용하는 것이 가장 효율적일 것으로 예상된다.
